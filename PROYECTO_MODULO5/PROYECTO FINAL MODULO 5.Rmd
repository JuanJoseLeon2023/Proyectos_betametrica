---
title: "PROYECTO FINAL MODULO 5"
author: "JUAN JOSE LEON"
date: "2023-11-29"
output: github_document
---

# LLAMANDO LAS LIBRERÍAS Y DEPURANDO LA BASE DE DATOS

```{r librerias, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=12,fig.height=8,fig.align='center'}

# Cargando librerías

library(openxlsx)
library(cluster)
library(devtools)
library(factoextra)
library(fpc)
library(NbClust)
library(gridExtra)

# Cargando la base de datos

data <- read.xlsx("C:\\Users\\ASUS_PC\\Documents\\CURSOS RSTUDIO\\PROGRAMA EXPERTO EN CIENCIA DE DATOS\\BASES_DATOS_BASES\\MODULO 5 MACHINE LEARNING I\\MACHINE LEARNING 1\\parte 2\\BOL_BP_MAY_ 2017_PROYECTO.xlsx")

# Ajustando la base de datos

nombres <- data$BANCOS

# Nueva base normalizada

base <- as.data.frame(scale(data[,-1]))

# Asignando los nombres

row.names(base) <- nombres

```


# CONSTRUCCIÓN DE CLUSTER JERÁRQUICO

# Primera Opción:

Distancias: Euclidean

Método de Clasificación: ward.D

```{r jerarquico1, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=8,fig.height=6,fig.align='center'}

# Construyendo el primer cluster jerárquico

cluster1 <- hclust(dist(base, method = "euclidean"), 
                  method = "ward.D")

# Graficando

plot(cluster1, hang = -0.01, cex = 0.8)

# Diseñando 5 posibles segmentos generales

plot(cluster1, hang = -0.01, cex = 0.8)
rect.hclust(cluster1, k = 5, border = "red")

```


# Segunda Opción:

Distancias: maximum

Método de Clasificación: average

```{r jerarquico2, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=8,fig.height=6,fig.align='center'}

# Construyendo el segundo cluster jerárquico

cluster2 <- hclust(dist(base, method = "maximum"), 
                  method = "average")

# Graficando

plot(cluster2, hang = -0.01, cex = 0.8)

# Diseñando 5 posibles segmentos generales

plot(cluster2, hang = -0.01, cex = 0.8)
rect.hclust(cluster2, k = 5, border = "red")

```


# Comparando los 2 cluster jerárquicos construidos:

```{r comparajerarquico, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=11,fig.height=6,fig.align='center'}

par(mfrow = c(1,2))
plot(cluster1, hang = -0.01, cex = 0.8)
rect.hclust(cluster1, k = 5, border = "red");
plot(cluster2, hang = -0.01, cex = 0.8)
rect.hclust(cluster2, k = 5, border = "red")

```

Al cambiar las distancias y el método se obtiene que las agrupaciones son similares si se generalizan tres grupos; pero al ampliar el tamaño de grupos a 4 o 5 grupos generales como se observa en la gráfica, hay diferencias importantes en los cluster. La agrupación por 3 cluster se ratifica cuando se usan modelos no jerárquicos como se verá mas adelante.

Resaltan los casos de BpCapital y de Bp Visionfund Ecuador, que en las distingas agrupaciones probadas quedan en cluster separados o independientes. Así mismo, en las distintas combinaciones tienen a quedar en un mismo grupo los bancos Bp Delbank y BP Comercial de Manabi.


# CONSTRUCCIÓN DE CLUSTER NO JERÁRQUICO

```{r nojerarquico, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# Optimizando el número de cluster

clusteroptimo <- NbClust(base, distance = "euclidean", min.nc = 2, max.nc = 6, method = "ward.D", index = "all")

# Se concluye que el número de cluster óptimo es 3


# Cluster no jerárquico usando k medias: Se usan 3 cluster porque es el número optimizado anteriormente

kmedias <- kmeans(base, 3)

kmedias

# Cluster no jerárquico usando k medoid

medoides <- pam(base, 3)

medoides

# Graficando los dos cluster construidos:

gk <- fviz_cluster(kmedias, data = base)

gm <- fviz_cluster(medoides, data = base)

grupo <- grid.arrange(gk, gm, ncol = 2)


# Comprobando la capacidad de clasificación

# Método Kmedias = indicador de clasificación del 0.58

silueta <- silhouette(kmedias$cluster, dist(base, method = "euclidean"))

fviz_silhouette(silueta)

# Método k medoids = indicador de clasificación del 0.58

silueta <- silhouette(medoides$cluster, dist(base, method = "euclidean"))

fviz_silhouette(silueta)



```

Conclusión de Cluster No Jerárquico: personalmente, observo una mayor estabilidad en los grupos diseñados utilizando el algoritmo de k medoids ya que mantiene las agrupaciones construidas, mientras que K medias tiende a variar siempre que se vuelve a ejecutar el algoritmo.
