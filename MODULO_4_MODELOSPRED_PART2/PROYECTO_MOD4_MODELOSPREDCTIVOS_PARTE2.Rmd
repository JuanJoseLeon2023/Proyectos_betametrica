---
title: "PROYECTO_MOD4_MODELOSPREDCTIVOS_PARTE2"
author: "JUAN JOSE LEON"
date: "2023-11-27"
output: github_document
---

# LLAMANDO LAS LIBRERÍAS Y DEPURANDO LA BASE DE DATOS

```{r librerias, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=12,fig.height=8,fig.align='center'}

# Cargando librerías

library(dplyr)
library(foreign)
library(gmodels)
library(ResourceSelection)
library(ROCR)
library(Epi)
library(QuantPsyc)
library(ggplot2)
library(memisc)

# Cargando la base de datos

datos <- read.csv("C:\\Users\\ASUS_PC\\Documents\\CURSOS RSTUDIO\\PROGRAMA EXPERTO EN CIENCIA DE DATOS\\BASES_DATOS_BASES\\MODULO 4 MODELOS PREDICTIVOS II\\Base-y-presentacion_4681YE\\germancredit.csv")

# Seleccionando las variables definitivas para trabajar los modelos

names(datos)

datos <- datos[c("Default", "duration", "amount", "installment", "age","cards")]

datos <- datos %>% 
  mutate(edad2 = age * age)

```


# CONSTRUYENDO LOS MODELOS LOGIT Y PROBIT

```{r modelos, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# estimando los modelos logit y probit

# ----1) MODELO LOGIT----

logit <- glm(Default ~ ., family = binomial(logit), data = datos)
summary(logit)


# ----2) MODELO PROBIT----  

probit <- glm(Default ~ ., family = binomial(probit), data = datos)
summary(probit)


```


# CONTRASTES HOSMER - LEMESHOW

```{r contrastehl, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# H0: El modelo tiene bondad de ajuste
# H1: El modelo NO tiene bondad de ajuste


# ----1) MODELO LOGIT ----

hllogit <- hoslem.test(datos$Default, fitted(logit), g = 10)

hllogit

# Se puede observar que este contraste arroja un p-value de 0.4677, por lo cual se puede aceptar la hipótesis nula y se concluye que el
# modelo logit SI tiene bondad de ajuste



# ----2) MODELO PROBIT----

hlprobit <- hoslem.test(datos$Default, fitted(probit), g = 10)

hlprobit

# En el modelo probit, se obtiene un p-value de 0.4272, por lo cual se acepta la hipótesis nula y se concluye que el modelo sí tiene
# bondad de ajuste



```


# MATRIZ DE CONFUSIÓN, CURVAS ROC Y ÁREAS BAJO LA CURVA

1) MATRIZ DE CLASIFICACIÓN

```{r clasificacion, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# Definiendo el umbral como el promedio de las probabilidades calculadas:

thresholdlogit <- mean(fitted(logit))
thresholdprobit <- mean(fitted(probit))


# TABLAS DE CLASIFICACION

# ----1) MODELO LOGIT----

ClassLog(logit, datos$Default, cut = thresholdlogit)

# Conclusión: Al revisar la capacidad de clasificación global del modelo, se obtiene un Overall del 61.2%; se puede validar que 
# la capacidad predictiva sobre las observaciones clasificadas como 0 tiene un acierto de 63.43%, mientras que la capacidad de predecir
# los valores clasificados como 1 es del 56%


# ----2) MODELO PROBIT----

ClassLog(probit, datos$Default, cut = thresholdprobit)

# Conclusión; en este modelo, la capacidad de clasificación total (overall) es del 60.9%, presentando también una inclinación a predecir
# de mejor manera los valores 0 que los 1


# Por ahora, se obseva que utilizando la matriz de confusión, el modelo logit tiene una mejor capacidad de predicción global


```


2) CURVAS ROC Y ÁREAS BAJO LA CURVA

```{r curvasRoc, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}


# ---- 2.1) CURVA ROC MODELO LOGIT----

predlogit <- prediction(logit$fitted.values, datos$Default)

perflogit <- performance(predlogit, measure = "tpr", x.measure = "fpr")

plot(perflogit, colorize = T, lyt = 3)
abline(0, 1, col = "black")

# El área bajo la curva para el modelo logit corresponde a: 65.58952%

auclogit <- performance(predlogit, measure = "auc")
auclogit <- auclogit@y.values[[1]]
auclogit



# ---- 2.2) CURVA ROC MODELO PROBIT----

predprobit <- prediction(probit$fitted.values, datos$Default)

perfprobit <- performance(predprobit, measure = "tpr", x.measure = "fpr")

plot(perfprobit, colorize = T, lyt = 3)
abline(0, 1, col = "black")

# El área bajo la curva para el modelo probit corresponde a: 65.57667%

aucprobit <- performance(predprobit, measure = "auc")
aucprobit <- aucprobit@y.values[[1]]
aucprobit


# CONCLUSIÓN: utilizando la curva ROC y el área bajo la curva, también se concluye que el mejor modelo es el Logit

```


# PUNTO DE CORTE ÓPTIMO PARA CADA MODELO

```{r corteoptimo, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# Usando las siguientes librerías

library(reshape2)
library(gridExtra)
library(plotly)

# ----1) MODELO LOGIT ----

perflogit2 <- performance(predlogit, "sens", "spec")

senlogit <- slot(perflogit2, "y.values"[[1]])

esplogit <- slot(perflogit2, "x.values"[[1]])

alflogit <- slot(perflogit2, "alpha.values"[[1]])

# Generando una matriz con los objetos alf, sen, esp (alpha, sensitividad y especificidad) y renombrandolos

matlogit <- data.frame(alflogit, senlogit, esplogit)
names(matlogit)[1] <- "alflogit"
names(matlogit)[2] <- "senlogit"
names(matlogit)[3] <- "esplogit"

# Convirtiendo la mariz creada (matlogit) en tipo panel dejando como id o primera columna a "alf

mlogit <- melt(matlogit, id=c("alflogit"))

# Graficando

plogit <- ggplot(mlogit, aes(alflogit, value, group = variable, colour = variable))+
  geom_line(size = 1.2) +
  labs(title = "PUNTO DE CORTE OPTIMO LOGIT")

# CONCLUSIÓN: Con la siguiente gráfica, se puede concluir que el punto óptimo como umbral del modelo LOGIT es 28.7533%

thresholdlogitfinal <- 0.287533

plogit

# ggplotly(plogit)




# ----2) MODELO PROBIT ----

perfprobit2 <- performance(predprobit, "sens", "spec")

senprobit <- slot(perfprobit2, "y.values"[[1]])

espprobit <- slot(perfprobit2, "x.values"[[1]])

alfprobit <- slot(perfprobit2, "alpha.values"[[1]])

# Generando una matriz con los objetos alf, sen, esp (alpha, sensitividad y especificidad) y renombrandolos

matprobit <- data.frame(alfprobit, senprobit, espprobit)
names(matprobit)[1] <- "alfprobit"
names(matprobit)[2] <- "senprobit"
names(matprobit)[3] <- "espprobit"

# Convirtiendo la mariz creada (matprobit) en tipo panel dejando como id o primera columna a "alf

mprobit <- melt(matprobit, id=c("alfprobit"))

# Graficando

pprobit <- ggplot(mprobit, aes(alfprobit, value, group = variable, colour = variable))+
  geom_line(size = 1.2) +
  labs(title = "PUNTO DE CORTE OPTIMO PROBIT")

# CONCLUSIÓN: Con la siguiente gráfica, se puede concluir que el punto óptimo como umbral del modelo PROBIT es 28.9087%

thresholdprobitfinal <- 0.289087

pprobit

# ggplotly(pprobit)




```


# TABLAS DE CLASIFICACIÓN UTILIZANDO EL PUNTO ÓPTIMO CALCULADO PARA CADA MODELO

```{r clasificacionPuntoOptimo, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# ----1) MODELO LOGIT----

ClassLog(logit, datos$Default, cut = thresholdlogitfinal)

# Para el modelo logit, utilizando el umbral óptimo se tiene un porcentaje de clasificación global del 59.1% y las 
# clasificaciones tanto de los 0 como de los 1 tiende a un 59% de clasificación correcta


# ----2) MODELO PROBIT----

ClassLog(probit, datos$Default, cut = thresholdprobitfinal)

# El modelo logit, una vez ajustado el umbral óptimo presenta un 59.4% de clasificación global
# Respecto a los 1 y los 0 presenta unos porcentajes de clasificación correcta de 59.33% y 29.43% respectivamente


```


# PRONÓSTICOS REALIZADOS FUERA DE LA MUESTRA

```{r pronosticos, echo=TRUE, message=FALSE, warning=FALSE,comment="",fig.width=6,fig.height=4,fig.align='center'}

# Construyendo una nueva base con una observación adicional para el pronóstico

names(datos)

newdata <- data.frame(duration = 18, amount = 3500, installment = 2, age = 28, cards = 1, edad2 = (28*28))

# Haciendo las predicciones con cada modelo: 

# ----1) MODELO LOGIT----

predict(logit, newdata, type = "response")

# La probabilidad de que el deudor incumpla es del 27.47% con el modelo logit


# ----2) MODELO PROBIT----

predict(probit, newdata, type = "response")

# La probabilidad de que el deudor incumpla es del 27.73% con el modelo logit

```


# MODELO SELECCIONADO POR EL INVESTIGADOR

Si bien, una vez determinado el punto o umbral óptimo de corte, se estableció que el modelo con una mayor capacidad predictiva era el Probit, se selecciona al modelo logit como herramienta final de pronóstico.

Lo anterior, por cuanto el criterio de Hosmer - Lemeshow favorece al modelo logit, y así mismo, por cuanto presenta una mayor facilidad para la transformación de los datos obtenidos y de interpretación.
